{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f004a12-901e-4e86-b322-20a60b3dbfbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== HEAD ===\n",
      "     lesion_id      image_id   dx dx_type   age   sex localization\n",
      "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp\n",
      "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp\n",
      "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp\n",
      "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp\n",
      "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear\n",
      "\n",
      "=== INFO ===\n",
      "lesion_id        object\n",
      "image_id         object\n",
      "dx               object\n",
      "dx_type          object\n",
      "age             float64\n",
      "sex              object\n",
      "localization     object\n",
      "dtype: object\n",
      "\n",
      "=== SHAPE ===\n",
      "(10015, 7)\n",
      "\n",
      "=== MISSING VALUES ===\n",
      "age    57\n",
      "dtype: int64\n",
      "Saved missing values to eda_outputs\\missing_values.csv\n",
      "Saved descriptive stats to eda_outputs\\metadata_describe.csv\n",
      "Saved sample image grid\n",
      "\n",
      "EDA complete. Check the outputs in eda_outputs\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Exploratory Data Analysis (EDA) for HAM10000_metadata\n",
    "This version is Jupyter-friendly and does not require command-line arguments.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "# ===================== User Configuration =====================\n",
    "metadata_path = 'C:/Users/admin/Desktop/capstone project/capstone dataset/HAM10000_metadata.csv'\n",
    "images_dir = 'C:/Users/admin/Desktop/capstone project/capstone dataset/HAM10000_images'\n",
    "\n",
    "outdir = 'eda_outputs'\n",
    "sample_images_count = 16\n",
    "\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "# ===================== Functions =====================\n",
    "\n",
    "def overview(df, outdir):\n",
    "    print('\\n=== HEAD ===')\n",
    "    print(df.head())\n",
    "\n",
    "    print('\\n=== INFO ===')\n",
    "    print(df.dtypes)\n",
    "\n",
    "    print('\\n=== SHAPE ===')\n",
    "    print(df.shape)\n",
    "\n",
    "    print('\\n=== MISSING VALUES ===')\n",
    "    miss = df.isnull().sum().sort_values(ascending=False)\n",
    "    print(miss[miss>0])\n",
    "    miss.to_csv(os.path.join(outdir, 'missing_values.csv'))\n",
    "    print(f\"Saved missing values to {os.path.join(outdir, 'missing_values.csv')}\")\n",
    "\n",
    "\n",
    "def basic_stats(df, outdir):\n",
    "    stats = df.describe(include='all')\n",
    "    stats.to_csv(os.path.join(outdir, 'metadata_describe.csv'))\n",
    "    print(f\"Saved descriptive stats to {os.path.join(outdir, 'metadata_describe.csv')}\")\n",
    "A\n",
    "\n",
    "def plot_class_distribution(df, outdir, col='dx'):\n",
    "    counts = df[col].value_counts()\n",
    "    plt.figure(figsize=(10,6))\n",
    "    sns.barplot(x=counts.index, y=counts.values)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title(f'Distribution of {col} (lesion diagnosis)')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xlabel(col)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(outdir, 'class_distribution.png'))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_age_histogram(df, outdir, age_col='age'):\n",
    "    df_age = pd.to_numeric(df[age_col], errors='coerce')\n",
    "    plt.figure(figsize=(8,5))\n",
    "    sns.histplot(df_age.dropna(), bins=30)\n",
    "    plt.title('Age distribution')\n",
    "    plt.xlabel('Age')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(outdir, 'age_distribution.png'))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_sex_counts(df, outdir, sex_col='sex'):\n",
    "    counts = df[sex_col].value_counts(dropna=False)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.barplot(x=counts.index.astype(str), y=counts.values)\n",
    "    plt.title('Sex counts')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xlabel('Sex')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(outdir, 'sex_counts.png'))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_localization(df, outdir, loc_col='localization'):\n",
    "    top = df[loc_col].value_counts().head(20)\n",
    "    plt.figure(figsize=(10,6))\n",
    "    sns.barplot(y=top.index, x=top.values)\n",
    "    plt.title('Top 20 lesion localizations')\n",
    "    plt.xlabel('Count')\n",
    "    plt.ylabel('Localization')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(outdir, 'top_localizations.png'))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def correlation_heatmap(df, outdir):\n",
    "    df2 = df.copy()\n",
    "    for col in df2.select_dtypes(include='object').columns:\n",
    "        df2[col] = df2[col].astype('category').cat.codes\n",
    "    numeric = df2.select_dtypes(include=[np.number])\n",
    "    if numeric.shape[1] < 2:\n",
    "        print('Not enough numeric columns for correlation heatmap')\n",
    "        return\n",
    "    corr = numeric.corr()\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.heatmap(corr, annot=False, cmap='coolwarm', center=0)\n",
    "    plt.title('Correlation heatmap (object columns encoded)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(outdir, 'correlation_heatmap.png'))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def sample_images_grid(df, images_dir, outdir, image_id_col='image_id', n=16, size=(128,128)):\n",
    "    if not images_dir or not os.path.isdir(images_dir):\n",
    "        print('Images directory not found; skipping image grid')\n",
    "        return\n",
    "\n",
    "    samples = []\n",
    "    classes = df['dx'].unique()\n",
    "    per_class = max(1, n // max(1, len(classes)))\n",
    "    for c in classes:\n",
    "        rows = df[df['dx'] == c]\n",
    "        samples += rows[image_id_col].sample(min(per_class, len(rows))).tolist()\n",
    "        if len(samples) >= n:\n",
    "            break\n",
    "\n",
    "    if len(samples) < n:\n",
    "        samples += df[image_id_col].sample(n - len(samples)).tolist()\n",
    "\n",
    "    imgs = []\n",
    "    for iid in samples[:n]:\n",
    "        found = None\n",
    "        for ext in ['jpg','jpeg','png']:\n",
    "            p = os.path.join(images_dir, f'{iid}.{ext}')\n",
    "            if os.path.exists(p):\n",
    "                found = p\n",
    "                break\n",
    "        if not found:\n",
    "            for fname in os.listdir(images_dir):\n",
    "                if iid in fname:\n",
    "                    found = os.path.join(images_dir, fname)\n",
    "                    break\n",
    "        if found:\n",
    "            try:\n",
    "                im = Image.open(found).convert('RGB').resize(size)\n",
    "                imgs.append(im)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    if not imgs:\n",
    "        print('No images found; skipping image grid')\n",
    "        return\n",
    "\n",
    "    cols = int(np.sqrt(len(imgs)))\n",
    "    cols = max(1, cols)\n",
    "    rows = int(np.ceil(len(imgs)/cols))\n",
    "    grid = Image.new('RGB', (cols*size[0], rows*size[1]), color=(255,255,255))\n",
    "    for idx, im in enumerate(imgs):\n",
    "        x = (idx % cols) * size[0]\n",
    "        y = (idx // cols) * size[1]\n",
    "        grid.paste(im, (x,y))\n",
    "\n",
    "    grid.save(os.path.join(outdir, 'sample_image_grid.jpg'))\n",
    "    print('Saved sample image grid')\n",
    "\n",
    "# ===================== Main Execution =====================\n",
    "\n",
    "# Load metadata\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "\n",
    "# Overview & stats\n",
    "overview(metadata, outdir)\n",
    "basic_stats(metadata, outdir)\n",
    "\n",
    "# Plots\n",
    "if 'dx' in metadata.columns:\n",
    "    plot_class_distribution(metadata, outdir)\n",
    "if 'age' in metadata.columns:\n",
    "    plot_age_histogram(metadata, outdir)\n",
    "if 'sex' in metadata.columns:\n",
    "    plot_sex_counts(metadata, outdir)\n",
    "if 'localization' in metadata.columns:\n",
    "    plot_localization(metadata, outdir)\n",
    "\n",
    "correlation_heatmap(metadata, outdir)\n",
    "\n",
    "# Sample images\n",
    "sample_images_grid(metadata, images_dir, outdir, image_id_col='image_id', n=sample_images_count)\n",
    "\n",
    "print('\\nEDA complete. Check the outputs in', outdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17bb77b8-97ec-4e62-bbd0-624db466943a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92bf5cc7-d490-4a1c-a503-1da492d80bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "359d2ad7-dec9-4550-928a-ce054ef66705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.26.3"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\admin\\AppData\\Local\\Temp\\pip-uninstall-ypvw857s'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.3 which is incompatible.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.3 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached numpy-1.26.3-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Using cached numpy-1.26.3-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.3\n",
      "    Uninstalling numpy-1.26.3:\n",
      "      Successfully uninstalled numpy-1.26.3\n",
      "Successfully installed numpy-1.26.3\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install numpy==1.26.3 --force-reinstall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dffc824-9c0b-443a-908e-4e6ffc3bc814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing train set (7013 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7013/7013 [13:15<00:00,  8.81it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing val set (1499 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1499/1499 [01:44<00:00, 14.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test set (1503 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1084/1503 [01:18<00:28, 14.67it/s]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm  # for progress bar\n",
    "\n",
    "# ============================\n",
    "# ðŸ“ Paths\n",
    "# ============================\n",
    "image_dir = \"HAM10000_images\"\n",
    "metadata_path = \"HAM10000_metadata.csv\"\n",
    "out_dir = \"HAM10000_yolo_cls\"\n",
    "\n",
    "# Load metadata\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "\n",
    "# ============================\n",
    "# ðŸ· Class Mapping\n",
    "# ============================\n",
    "class_map = {\n",
    "    \"mel\": \"melanoma\",\n",
    "    \"nv\": \"melanocytic_nevus\",\n",
    "    \"bcc\": \"basal_cell_carcinoma\",\n",
    "    \"akiec\": \"actinic_keratosis\",\n",
    "    \"bkl\": \"benign_keratosis\",\n",
    "    \"df\": \"dermatofibroma\",\n",
    "    \"vasc\": \"vascular_lesions\"\n",
    "}\n",
    "\n",
    "# ============================\n",
    "# ðŸ”§ Preprocessing Functions\n",
    "# ============================\n",
    "\n",
    "# Resize with aspect ratio padding (640x640)\n",
    "def resize_with_padding(image, target_size=640):\n",
    "    h, w = image.shape[:2]\n",
    "    scale = target_size / max(h, w)\n",
    "    nh, nw = int(h * scale), int(w * scale)\n",
    "    resized = cv2.resize(image, (nw, nh))\n",
    "    new_img = cv2.copyMakeBorder(\n",
    "        resized,\n",
    "        (target_size - nh) // 2,\n",
    "        (target_size - nh + 1) // 2,\n",
    "        (target_size - nw) // 2,\n",
    "        (target_size - nw + 1) // 2,\n",
    "        cv2.BORDER_CONSTANT, value=(0, 0, 0)\n",
    "    )\n",
    "    return new_img\n",
    "\n",
    "# CLAHE (Contrast normalization)\n",
    "def apply_clahe(image):\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    l = clahe.apply(l)\n",
    "    merged = cv2.merge((l, a, b))\n",
    "    return cv2.cvtColor(merged, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "# Noise reduction (Median Filtering)\n",
    "def reduce_noise(image):\n",
    "    return cv2.medianBlur(image, 3)\n",
    "\n",
    "# ============================\n",
    "# ðŸ§© Split Dataset (70/15/15)\n",
    "# ============================\n",
    "train_df, test_df = train_test_split(metadata, test_size=0.15, stratify=metadata['dx'], random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.176, stratify=train_df['dx'], random_state=42)\n",
    "splits = {\"train\": train_df, \"val\": val_df, \"test\": test_df}\n",
    "\n",
    "# ============================\n",
    "# ðŸ–¼ Process and Save Images\n",
    "# ============================\n",
    "for split, df in splits.items():\n",
    "    print(f\"Processing {split} set ({len(df)} images)...\")\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        img_name = row[\"image_id\"] + \".jpg\"\n",
    "        src = os.path.join(image_dir, img_name)\n",
    "        if not os.path.exists(src):\n",
    "            continue\n",
    "\n",
    "        # --- Read and preprocess ---\n",
    "        img = cv2.imread(src)\n",
    "        img = resize_with_padding(img, 640)\n",
    "        img = apply_clahe(img)\n",
    "        img = reduce_noise(img)\n",
    "\n",
    "        \n",
    "        label = class_map[row[\"dx\"]]\n",
    "        save_dir = os.path.join(out_dir, split, label)\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        save_path = os.path.join(save_dir, img_name)\n",
    "        cv2.imwrite(save_path, img)\n",
    "\n",
    "print(\" YOLOv9-ready dataset created at:\", out_dir)\n",
    "print(\"Includes: CLAHE, Median Filtering, 640Ã—640 normalization (no augmentation)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2280509-06f3-4d45-b9d1-3ea62005956a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Torch: 2.9.0+cpu\n",
      "âœ… CUDA available: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\admin\\anaconda3\\Lib\\site-packages\\~umpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\admin\\anaconda3\\Lib\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 3.5.0 requires fsspec[http]<=2024.12.0,>=2023.1.0, but you have fsspec 2025.10.0 which is incompatible.\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.6 which is incompatible.\n",
      "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.16.3 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\n",
      "streamlit 1.37.1 requires packaging<25,>=20, but you have packaging 25.0 which is incompatible.\n",
      "streamlit 1.37.1 requires pillow<11,>=7.1.0, but you have pillow 12.0.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics torch torchvision torchaudio --quiet\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "print(\"âœ… Torch:\", torch.__version__)\n",
    "print(\"âœ… CUDA available:\", torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "290139f6-4c72-4907-84b6-7b3570346fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics.utils.downloads import safe_download\n",
    "\n",
    "# Download YOLOv9 classification weights\n",
    "safe_download('https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov9c-cls.pt', dir='.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5252f5f5-9116-44ea-8622-18e5f4e617bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n-cls.pt to 'yolov8n-cls.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.31M/5.31M [00:00<00:00, 11.7MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.225 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.5  Python-3.12.7 torch-2.9.0+cpu CPU (12th Gen Intel Core(TM) i7-1255U)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=HAM10000_yolo_cls, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs_skin_cancer, name=yolov8_skin_cls, exist_ok=False, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs_skin_cancer\\yolov8_skin_cls\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\admin\\Desktop\\capstone project\\capstone dataset\\HAM10000_yolo_cls\\train... found 7013 images in 7 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\admin\\Desktop\\capstone project\\capstone dataset\\HAM10000_yolo_cls\\val... found 1499 images in 7 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\admin\\Desktop\\capstone project\\capstone dataset\\HAM10000_yolo_cls\\test... found 1503 images in 7 classes  \n",
      "Overriding model.yaml nc=1000 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    339207  ultralytics.nn.modules.head.Classify         [256, 7]                      \n",
      "YOLOv8n-cls summary: 99 layers, 1,447,255 parameters, 1,447,255 gradients, 3.4 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\admin\\Desktop\\capstone project\\capstone dataset\\HAM10000_yolo_cls\\train... 7013 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7013/7013 [00:08<00:00, 782.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\admin\\Desktop\\capstone project\\capstone dataset\\HAM10000_yolo_cls\\train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\admin\\Desktop\\capstone project\\capstone dataset\\HAM10000_yolo_cls\\val... 1499 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1499/1499 [00:02<00:00, 532.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\admin\\Desktop\\capstone project\\capstone dataset\\HAM10000_yolo_cls\\val.cache\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001, momentum=0.937) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns_skin_cancer\\yolov8_skin_cls\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50         0G      1.913         16        640:   0%|          | 1/439 [00:04<31:55,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://ultralytics.com/assets/Arial.ttf to 'C:\\Users\\admin\\AppData\\Roaming\\Ultralytics\\Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 10.7MB/s]\n",
      "       1/50         0G     0.9402          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [24:27<00:00,  3.34s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [01:31<00:00,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.662      0.987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50         0G     0.8383          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [23:50<00:00,  3.26s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [01:29<00:00,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.72      0.993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/50         0G     0.7804          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [23:48<00:00,  3.25s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [01:33<00:00,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.697      0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/50         0G     0.7336          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [23:39<00:00,  3.23s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [01:31<00:00,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.759      0.993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/50         0G      0.699          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [23:44<00:00,  3.25s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [01:32<00:00,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.756      0.988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/50         0G     0.6843          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [23:45<00:00,  3.25s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [01:32<00:00,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.728      0.991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/50         0G     0.6444          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [23:37<00:00,  3.23s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [01:31<00:00,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.771      0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/50         0G     0.6338          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [23:39<00:00,  3.23s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [01:32<00:00,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.755      0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/50         0G     0.6116          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [23:45<00:00,  3.25s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [01:31<00:00,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.794      0.997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/50         0G      0.607          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [23:56<00:00,  3.27s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [01:35<00:00,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.758      0.997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/50         0G     0.6088          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [31:30<00:00,  4.31s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [01:42<00:00,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.787      0.996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/50         0G      0.576          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [29:06<00:00,  3.98s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [01:43<00:00,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.779      0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/50         0G     0.5676          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [29:21<00:00,  4.01s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [01:43<00:00,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.819      0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/50         0G     0.5561          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [31:20<00:00,  4.28s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [01:49<00:00,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.804      0.997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/50         0G     0.5376          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [29:08<00:00,  3.98s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [01:49<00:00,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.812      0.997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/50         0G     0.5427          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [29:25<00:00,  4.02s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [01:50<00:00,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.828      0.997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/50         0G     0.5258          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [29:18<00:00,  4.01s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [01:52<00:00,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.833      0.997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/50         0G     0.4994          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [29:07<00:00,  3.98s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [01:48<00:00,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.81          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/50         0G     0.4962          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [29:15<00:00,  4.00s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [01:43<00:00,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.767      0.998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/50         0G     0.4971          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [29:20<00:00,  4.01s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [01:50<00:00,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.809      0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/50         0G     0.4688          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [29:35<00:00,  4.04s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [01:50<00:00,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.833      0.998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/50         0G     0.4569          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [29:25<00:00,  4.02s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [01:48<00:00,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.817      0.996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/50         0G     0.4711          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [29:31<00:00,  4.04s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [01:49<00:00,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.811      0.998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/50         0G     0.4587          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [29:29<00:00,  4.03s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [01:48<00:00,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.813      0.998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/50         0G     0.4383          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [29:35<00:00,  4.04s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [01:49<00:00,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.811      0.998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/50         0G     0.4262          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [29:47<00:00,  4.07s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [01:49<00:00,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.836      0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/50         0G     0.4157          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [29:37<00:00,  4.05s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [01:48<00:00,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.82      0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/50         0G     0.4167          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [29:19<00:00,  4.01s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [01:49<00:00,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.823      0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/50         0G      0.417          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [29:31<00:00,  4.04s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [01:48<00:00,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.808          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/50         0G     0.4029          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [29:24<00:00,  4.02s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [01:48<00:00,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.832      0.996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/50         0G     0.3848          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [29:23<00:00,  4.02s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [01:48<00:00,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.828      0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/50         0G       0.38          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [29:14<00:00,  4.00s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [01:50<00:00,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.835      0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/50         0G     0.3599          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [29:30<00:00,  4.03s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [01:49<00:00,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.839      0.997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/50         0G     0.3684          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [29:37<00:00,  4.05s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [01:51<00:00,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.835      0.998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/50         0G     0.3485          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [29:11<00:00,  3.99s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [01:49<00:00,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.851      0.997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/50         0G     0.3386          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [29:12<00:00,  3.99s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [01:48<00:00,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.835      0.997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/50         0G     0.3222          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [29:16<00:00,  4.00s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [01:48<00:00,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.843      0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/50         0G     0.3143          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [29:22<00:00,  4.02s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [01:51<00:00,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.827      0.998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/50         0G     0.3049          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [29:17<00:00,  4.00s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [01:48<00:00,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.834      0.997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/50         0G     0.2972          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [29:16<00:00,  4.00s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [01:48<00:00,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.845      0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "      41/50         0G     0.2885          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [29:12<00:00,  3.99s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [01:50<00:00,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.848      0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      42/50         0G     0.2812          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [28:48<00:00,  3.94s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [01:48<00:00,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.854      0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      43/50         0G     0.2784          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [28:18<00:00,  3.87s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [01:48<00:00,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.839      0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      44/50         0G     0.2705          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [28:16<00:00,  3.86s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [01:49<00:00,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.853      0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      45/50         0G     0.2634          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [28:07<00:00,  3.84s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [01:46<00:00,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.855      0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      46/50         0G     0.2373          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [28:13<00:00,  3.86s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [01:48<00:00,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.848      0.998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      47/50         0G     0.2456          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [28:16<00:00,  3.86s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [01:45<00:00,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.847      0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      48/50         0G     0.2386          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [28:17<00:00,  3.87s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [01:50<00:00,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.845      0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      49/50         0G     0.2319          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [28:58<00:00,  3.96s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [01:46<00:00,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.849      0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      50/50         0G     0.2294          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [29:21<00:00,  4.01s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [01:51<00:00,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.846      0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "50 epochs completed in 24.967 hours.\n",
      "Optimizer stripped from runs_skin_cancer\\yolov8_skin_cls\\weights\\last.pt, 3.0MB\n",
      "Optimizer stripped from runs_skin_cancer\\yolov8_skin_cls\\weights\\best.pt, 3.0MB\n",
      "\n",
      "Validating runs_skin_cancer\\yolov8_skin_cls\\weights\\best.pt...\n",
      "Ultralytics 8.3.5  Python-3.12.7 torch-2.9.0+cpu CPU (12th Gen Intel Core(TM) i7-1255U)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 1,443,847 parameters, 0 gradients, 3.3 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\admin\\Desktop\\capstone project\\capstone dataset\\HAM10000_yolo_cls\\train... found 7013 images in 7 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\admin\\Desktop\\capstone project\\capstone dataset\\HAM10000_yolo_cls\\val... found 1499 images in 7 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\admin\\Desktop\\capstone project\\capstone dataset\\HAM10000_yolo_cls\\test... found 1503 images in 7 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [01:40<00:00,  2.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.855      0.999\n",
      "Speed: 0.0ms preprocess, 45.5ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns_skin_cancer\\yolov8_skin_cls\u001b[0m\n",
      "Results saved to \u001b[1mruns_skin_cancer\\yolov8_skin_cls\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# ðŸ§  Train YOLOv8 on Skin Cancer Dataset\n",
    "# ==========================\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLOv8 classification model (pretrained on ImageNet)\n",
    "model = YOLO(\"yolov8n-cls.pt\")  # you can try yolov8s-cls.pt for better accuracy\n",
    "\n",
    "# Train on your preprocessed dataset\n",
    "results = model.train(\n",
    "    data=\"HAM10000_yolo_cls\",  # your dataset root folder\n",
    "    epochs=50,                 # you can increase to 100 for better accuracy\n",
    "    imgsz=640,                 # image size (same as preprocessing)\n",
    "    batch=16,                  # adjust based on your system memory\n",
    "    lr0=0.001,                 # learning rate\n",
    "    optimizer=\"Adam\",          # optimizer choice (SGD/Adam)\n",
    "    project=\"runs_skin_cancer\",# save folder for all experiments\n",
    "    name=\"yolov8_skin_cls\",    # experiment name\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35f35bb0-d8ad-48a7-b4d0-0d5d04208527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.5  Python-3.12.7 torch-2.9.0+cpu CPU (12th Gen Intel Core(TM) i7-1255U)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 1,443,847 parameters, 0 gradients, 3.3 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\admin\\Desktop\\capstone project\\capstone dataset\\HAM10000_yolo_cls\\train... found 7013 images in 7 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\admin\\Desktop\\capstone project\\capstone dataset\\HAM10000_yolo_cls\\val... found 1499 images in 7 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\admin\\Desktop\\capstone project\\capstone dataset\\HAM10000_yolo_cls\\test... found 1503 images in 7 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\admin\\Desktop\\capstone project\\capstone dataset\\HAM10000_yolo_cls\\val... 1499 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1499/1499 [00:00<?, ?it/s]\n",
      "C:\\Users\\admin\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [01:46<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.855      0.999\n",
      "Speed: 0.0ms preprocess, 49.9ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\val\u001b[0m\n",
      "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
      "\n",
      "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x0000016EE9C99DF0>\n",
      "curves: []\n",
      "curves_results: []\n",
      "fitness: 0.9266177415847778\n",
      "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
      "results_dict: {'metrics/accuracy_top1': 0.8545697331428528, 'metrics/accuracy_top5': 0.9986657500267029, 'fitness': 0.9266177415847778}\n",
      "save_dir: WindowsPath('runs/classify/val')\n",
      "speed: {'preprocess': 0.012427031635999522, 'inference': 49.87871813885445, 'loss': 0.0, 'postprocess': 0.0}\n",
      "task: 'classify'\n",
      "top1: 0.8545697331428528\n",
      "top5: 0.9986657500267029\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load trained model\n",
    "model = YOLO(r\"C:\\Users\\admin\\Desktop\\capstone project\\capstone dataset\\runs_skin_cancer\\yolov8_skin_cls\\weights\\best.pt\")\n",
    "\n",
    "# Evaluate performance on validation or test data\n",
    "metrics = model.val(data=\"HAM10000_yolo_cls\", imgsz=640, batch=16)\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7173548b-dbb5-40b4-971a-c4af2f17817c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\admin\\Desktop\\capstone project\\capstone dataset\\HAM10000_yolo_cls\\test\\melanoma\\ISIC_0030107.jpg: 640x640 melanocytic_nevus 0.96, melanoma 0.03, actinic_keratosis 0.01, benign_keratosis 0.00, dermatofibroma 0.00, 112.6ms\n",
      "Speed: 19.6ms preprocess, 112.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\classify\\predict3\u001b[0m\n",
      "Predicted class: melanocytic_nevus (0.96 confidence)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(r\"C:\\Users\\admin\\Desktop\\capstone project\\capstone dataset\\runs_skin_cancer\\yolov8_skin_cls\\weights\\best.pt\")\n",
    "\n",
    "# Predict on one test image\n",
    "result = model.predict(\n",
    "    source=r\"C:\\Users\\admin\\Desktop\\capstone project\\capstone dataset\\HAM10000_yolo_cls\\test\\melanoma\\ISIC_0030107.jpg\",\n",
    "    save=True,\n",
    "    show=True\n",
    ")\n",
    "\n",
    "# Display predicted class and confidence\n",
    "probs = result[0].probs\n",
    "print(f\"Predicted class: {model.names[probs.top1]} ({probs.top1conf:.2f} confidence)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a631b27-8f8c-4be6-9912-77f2a6755dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
