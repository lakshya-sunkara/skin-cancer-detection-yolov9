{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f004a12-901e-4e86-b322-20a60b3dbfbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== HEAD ===\n",
      "     lesion_id      image_id   dx dx_type   age   sex localization\n",
      "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp\n",
      "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp\n",
      "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp\n",
      "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp\n",
      "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear\n",
      "\n",
      "=== INFO ===\n",
      "lesion_id        object\n",
      "image_id         object\n",
      "dx               object\n",
      "dx_type          object\n",
      "age             float64\n",
      "sex              object\n",
      "localization     object\n",
      "dtype: object\n",
      "\n",
      "=== SHAPE ===\n",
      "(10015, 7)\n",
      "\n",
      "=== MISSING VALUES ===\n",
      "age    57\n",
      "dtype: int64\n",
      "Saved missing values to eda_outputs\\missing_values.csv\n",
      "Saved descriptive stats to eda_outputs\\metadata_describe.csv\n",
      "Saved sample image grid\n",
      "\n",
      "EDA complete. Check the outputs in eda_outputs\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Exploratory Data Analysis (EDA) for HAM10000_metadata\n",
    "This version is Jupyter-friendly and does not require command-line arguments.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "# ===================== User Configuration =====================\n",
    "metadata_path = 'C:/Users/admin/Desktop/capstone project/capstone dataset/HAM10000_metadata.csv'\n",
    "images_dir = 'C:/Users/admin/Desktop/capstone project/capstone dataset/HAM10000_images'\n",
    "\n",
    "outdir = 'eda_outputs'\n",
    "sample_images_count = 16\n",
    "\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "# ===================== Functions =====================\n",
    "\n",
    "def overview(df, outdir):\n",
    "    print('\\n=== HEAD ===')\n",
    "    print(df.head())\n",
    "\n",
    "    print('\\n=== INFO ===')\n",
    "    print(df.dtypes)\n",
    "\n",
    "    print('\\n=== SHAPE ===')\n",
    "    print(df.shape)\n",
    "\n",
    "    print('\\n=== MISSING VALUES ===')\n",
    "    miss = df.isnull().sum().sort_values(ascending=False)\n",
    "    print(miss[miss>0])\n",
    "    miss.to_csv(os.path.join(outdir, 'missing_values.csv'))\n",
    "    print(f\"Saved missing values to {os.path.join(outdir, 'missing_values.csv')}\")\n",
    "\n",
    "\n",
    "def basic_stats(df, outdir):\n",
    "    stats = df.describe(include='all')\n",
    "    stats.to_csv(os.path.join(outdir, 'metadata_describe.csv'))\n",
    "    print(f\"Saved descriptive stats to {os.path.join(outdir, 'metadata_describe.csv')}\")\n",
    "A\n",
    "\n",
    "def plot_class_distribution(df, outdir, col='dx'):\n",
    "    counts = df[col].value_counts()\n",
    "    plt.figure(figsize=(10,6))\n",
    "    sns.barplot(x=counts.index, y=counts.values)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title(f'Distribution of {col} (lesion diagnosis)')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xlabel(col)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(outdir, 'class_distribution.png'))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_age_histogram(df, outdir, age_col='age'):\n",
    "    df_age = pd.to_numeric(df[age_col], errors='coerce')\n",
    "    plt.figure(figsize=(8,5))\n",
    "    sns.histplot(df_age.dropna(), bins=30)\n",
    "    plt.title('Age distribution')\n",
    "    plt.xlabel('Age')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(outdir, 'age_distribution.png'))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_sex_counts(df, outdir, sex_col='sex'):\n",
    "    counts = df[sex_col].value_counts(dropna=False)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.barplot(x=counts.index.astype(str), y=counts.values)\n",
    "    plt.title('Sex counts')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xlabel('Sex')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(outdir, 'sex_counts.png'))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_localization(df, outdir, loc_col='localization'):\n",
    "    top = df[loc_col].value_counts().head(20)\n",
    "    plt.figure(figsize=(10,6))\n",
    "    sns.barplot(y=top.index, x=top.values)\n",
    "    plt.title('Top 20 lesion localizations')\n",
    "    plt.xlabel('Count')\n",
    "    plt.ylabel('Localization')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(outdir, 'top_localizations.png'))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def correlation_heatmap(df, outdir):\n",
    "    df2 = df.copy()\n",
    "    for col in df2.select_dtypes(include='object').columns:\n",
    "        df2[col] = df2[col].astype('category').cat.codes\n",
    "    numeric = df2.select_dtypes(include=[np.number])\n",
    "    if numeric.shape[1] < 2:\n",
    "        print('Not enough numeric columns for correlation heatmap')\n",
    "        return\n",
    "    corr = numeric.corr()\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.heatmap(corr, annot=False, cmap='coolwarm', center=0)\n",
    "    plt.title('Correlation heatmap (object columns encoded)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(outdir, 'correlation_heatmap.png'))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def sample_images_grid(df, images_dir, outdir, image_id_col='image_id', n=16, size=(128,128)):\n",
    "    if not images_dir or not os.path.isdir(images_dir):\n",
    "        print('Images directory not found; skipping image grid')\n",
    "        return\n",
    "\n",
    "    samples = []\n",
    "    classes = df['dx'].unique()\n",
    "    per_class = max(1, n // max(1, len(classes)))\n",
    "    for c in classes:\n",
    "        rows = df[df['dx'] == c]\n",
    "        samples += rows[image_id_col].sample(min(per_class, len(rows))).tolist()\n",
    "        if len(samples) >= n:\n",
    "            break\n",
    "\n",
    "    if len(samples) < n:\n",
    "        samples += df[image_id_col].sample(n - len(samples)).tolist()\n",
    "\n",
    "    imgs = []\n",
    "    for iid in samples[:n]:\n",
    "        found = None\n",
    "        for ext in ['jpg','jpeg','png']:\n",
    "            p = os.path.join(images_dir, f'{iid}.{ext}')\n",
    "            if os.path.exists(p):\n",
    "                found = p\n",
    "                break\n",
    "        if not found:\n",
    "            for fname in os.listdir(images_dir):\n",
    "                if iid in fname:\n",
    "                    found = os.path.join(images_dir, fname)\n",
    "                    break\n",
    "        if found:\n",
    "            try:\n",
    "                im = Image.open(found).convert('RGB').resize(size)\n",
    "                imgs.append(im)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    if not imgs:\n",
    "        print('No images found; skipping image grid')\n",
    "        return\n",
    "\n",
    "    cols = int(np.sqrt(len(imgs)))\n",
    "    cols = max(1, cols)\n",
    "    rows = int(np.ceil(len(imgs)/cols))\n",
    "    grid = Image.new('RGB', (cols*size[0], rows*size[1]), color=(255,255,255))\n",
    "    for idx, im in enumerate(imgs):\n",
    "        x = (idx % cols) * size[0]\n",
    "        y = (idx // cols) * size[1]\n",
    "        grid.paste(im, (x,y))\n",
    "\n",
    "    grid.save(os.path.join(outdir, 'sample_image_grid.jpg'))\n",
    "    print('Saved sample image grid')\n",
    "\n",
    "# ===================== Main Execution =====================\n",
    "\n",
    "# Load metadata\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "\n",
    "# Overview & stats\n",
    "overview(metadata, outdir)\n",
    "basic_stats(metadata, outdir)\n",
    "\n",
    "# Plots\n",
    "if 'dx' in metadata.columns:\n",
    "    plot_class_distribution(metadata, outdir)\n",
    "if 'age' in metadata.columns:\n",
    "    plot_age_histogram(metadata, outdir)\n",
    "if 'sex' in metadata.columns:\n",
    "    plot_sex_counts(metadata, outdir)\n",
    "if 'localization' in metadata.columns:\n",
    "    plot_localization(metadata, outdir)\n",
    "\n",
    "correlation_heatmap(metadata, outdir)\n",
    "\n",
    "# Sample images\n",
    "sample_images_grid(metadata, images_dir, outdir, image_id_col='image_id', n=sample_images_count)\n",
    "\n",
    "print('\\nEDA complete. Check the outputs in', outdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17bb77b8-97ec-4e62-bbd0-624db466943a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92bf5cc7-d490-4a1c-a503-1da492d80bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "359d2ad7-dec9-4550-928a-ce054ef66705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.26.3"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\admin\\AppData\\Local\\Temp\\pip-uninstall-ypvw857s'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.3 which is incompatible.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.3 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached numpy-1.26.3-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Using cached numpy-1.26.3-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.3\n",
      "    Uninstalling numpy-1.26.3:\n",
      "      Successfully uninstalled numpy-1.26.3\n",
      "Successfully installed numpy-1.26.3\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install numpy==1.26.3 --force-reinstall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dffc824-9c0b-443a-908e-4e6ffc3bc814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing train set (7013 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7013/7013 [13:15<00:00,  8.81it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing val set (1499 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1499/1499 [01:44<00:00, 14.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test set (1503 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1084/1503 [01:18<00:28, 14.67it/s]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm  # for progress bar\n",
    "\n",
    "# ============================\n",
    "# ðŸ“ Paths\n",
    "# ============================\n",
    "image_dir = \"HAM10000_images\"\n",
    "metadata_path = \"HAM10000_metadata.csv\"\n",
    "out_dir = \"HAM10000_yolo_cls\"\n",
    "\n",
    "# Load metadata\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "\n",
    "# ============================\n",
    "# ðŸ· Class Mapping\n",
    "# ============================\n",
    "class_map = {\n",
    "    \"mel\": \"melanoma\",\n",
    "    \"nv\": \"melanocytic_nevus\",\n",
    "    \"bcc\": \"basal_cell_carcinoma\",\n",
    "    \"akiec\": \"actinic_keratosis\",\n",
    "    \"bkl\": \"benign_keratosis\",\n",
    "    \"df\": \"dermatofibroma\",\n",
    "    \"vasc\": \"vascular_lesions\"\n",
    "}\n",
    "\n",
    "# ============================\n",
    "# ðŸ”§ Preprocessing Functions\n",
    "# ============================\n",
    "\n",
    "# Resize with aspect ratio padding (640x640)\n",
    "def resize_with_padding(image, target_size=640):\n",
    "    h, w = image.shape[:2]\n",
    "    scale = target_size / max(h, w)\n",
    "    nh, nw = int(h * scale), int(w * scale)\n",
    "    resized = cv2.resize(image, (nw, nh))\n",
    "    new_img = cv2.copyMakeBorder(\n",
    "        resized,\n",
    "        (target_size - nh) // 2,\n",
    "        (target_size - nh + 1) // 2,\n",
    "        (target_size - nw) // 2,\n",
    "        (target_size - nw + 1) // 2,\n",
    "        cv2.BORDER_CONSTANT, value=(0, 0, 0)\n",
    "    )\n",
    "    return new_img\n",
    "\n",
    "# CLAHE (Contrast normalization)\n",
    "def apply_clahe(image):\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    l = clahe.apply(l)\n",
    "    merged = cv2.merge((l, a, b))\n",
    "    return cv2.cvtColor(merged, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "# Noise reduction (Median Filtering)\n",
    "def reduce_noise(image):\n",
    "    return cv2.medianBlur(image, 3)\n",
    "\n",
    "# ============================\n",
    "# ðŸ§© Split Dataset (70/15/15)\n",
    "# ============================\n",
    "train_df, test_df = train_test_split(metadata, test_size=0.15, stratify=metadata['dx'], random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.176, stratify=train_df['dx'], random_state=42)\n",
    "splits = {\"train\": train_df, \"val\": val_df, \"test\": test_df}\n",
    "\n",
    "# ============================\n",
    "# ðŸ–¼ Process and Save Images\n",
    "# ============================\n",
    "for split, df in splits.items():\n",
    "    print(f\"Processing {split} set ({len(df)} images)...\")\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        img_name = row[\"image_id\"] + \".jpg\"\n",
    "        src = os.path.join(image_dir, img_name)\n",
    "        if not os.path.exists(src):\n",
    "            continue\n",
    "\n",
    "        # --- Read and preprocess ---\n",
    "        img = cv2.imread(src)\n",
    "        img = resize_with_padding(img, 640)\n",
    "        img = apply_clahe(img)\n",
    "        img = reduce_noise(img)\n",
    "\n",
    "        \n",
    "        label = class_map[row[\"dx\"]]\n",
    "        save_dir = os.path.join(out_dir, split, label)\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        save_path = os.path.join(save_dir, img_name)\n",
    "        cv2.imwrite(save_path, img)\n",
    "\n",
    "print(\" YOLOv9-ready dataset created at:\", out_dir)\n",
    "print(\"Includes: CLAHE, Median Filtering, 640Ã—640 normalization (no augmentation)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2280509-06f3-4d45-b9d1-3ea62005956a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
